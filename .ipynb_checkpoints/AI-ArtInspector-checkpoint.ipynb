{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c603f4-cba9-49a8-9398-4aa860d923b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "import os\n",
    "\n",
    "# Directory paths\n",
    "data_dir = \"data/\"\n",
    "models_dir = \"models/\"\n",
    "\n",
    "# Create the models directory if it doesn't exist\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "# Load categories you're interested in\n",
    "categories = ['alarm-clock', 'airplane', 'apple', 'banana', 'beach', 'bicycle', 'bridge', 'EiffelTower']\n",
    "#categories = ['alarm-clock', 'airplane', 'apple']\n",
    "\n",
    "# Function to load data for a given category\n",
    "def load_data(category):\n",
    "    file_path = f\"{data_dir}{category}.npy\"\n",
    "    data = np.load(file_path, allow_pickle=True)\n",
    "    return data\n",
    "\n",
    "# Resize image to match MobileNet input size\n",
    "def preprocess_image(img):\n",
    "    #img = cv2.resize(img, (224, 224))\n",
    "    #img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    #if len(img.shape) == 2:  # Grayscale image (single channel)\n",
    "    #    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Resize the image to the target size\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "    img = np.repeat(img, 3, axis=2)\n",
    "\n",
    "\n",
    "    # Handle batch dimension (depending on your data structure)\n",
    "    #if len(img.shape) == 3:  # Single image, add batch dimension\n",
    "    #    img = np.expand_dims(img, axis=0)  # Add batch dimension for a single image\n",
    "\n",
    "    \n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# Load MobileNet model without top layer\n",
    "# Load weights from the local file\n",
    "#base_model = MobileNet(weights='models/mobilenet_1_0_224_tf_no_top.h5', include_top=False, input_shape=(224, 224,3))\n",
    "base_model = MobileNet(weights='models/mobilenet_1_0_224_tf_no_top.h5', include_top=False, input_shape=(224, 224,3))\n",
    "\n",
    "# Add classification head\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "predictions = tf.keras.layers.Dense(len(categories), activation='softmax')(x)\n",
    "\n",
    "# Combine base model with classification head\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6893e5f-ec28-45d0-b2ba-894f3bc50bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'alarm-clock'  # Modify this line to specify the category\n",
    "data0 = load_data(category)\n",
    "data0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb6eac-d62d-40ae-8e6d-66640b814aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'airplane'  # Modify this line to specify the category\n",
    "data1 = load_data(category)\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d8a34-cd41-45a7-9bb5-370490ffb812",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'apple'  # Modify this line to specify the category\n",
    "data2 = load_data(category)\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5bda2b-747f-45ca-a778-c135a42e9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'banana'  # Modify this line to specify the category\n",
    "data3 = load_data(category)\n",
    "data3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20645111-03f9-4f9d-8631-e793a8ac8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'beach'  # Modify this line to specify the category\n",
    "data4 = load_data(category)\n",
    "data4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b8565-6340-4392-9e2e-197666242aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'bicycle'  # Modify this line to specify the category\n",
    "data5 = load_data(category)\n",
    "data5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1caa745-679d-45e4-bf9f-a5a73842078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'bridge'  # Modify this line to specify the category\n",
    "data6 = load_data(category)\n",
    "data6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a47146-32af-44d6-84e1-d9b0d32bf04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'EiffelTower'  # Modify this line to specify the category\n",
    "data7 = load_data(category)\n",
    "data7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c1b9e-24dd-41b4-ace7-a7cc9162a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming arr1, arr2, ..., arrN are your NumPy arrays\n",
    "# Each array has the same number of columns but potentially different numbers of rows\n",
    "\n",
    "# Determine the number of rows in each array\n",
    "num_rows0 = data0.shape[0]\n",
    "num_rows1 = data1.shape[0]\n",
    "num_rows2 = data2.shape[0]\n",
    "num_rows3 = data3.shape[0]\n",
    "num_rows4 = data4.shape[0]\n",
    "num_rows5 = data5.shape[0]\n",
    "num_rows6 = data6.shape[0]\n",
    "num_rows7 = data7.shape[0]\n",
    "# Repeat for arr3, arr4, ..., arrN\n",
    "\n",
    "# Choose the number of rows to select from each array (can be the same or different)\n",
    "num_rows_to_select = 10000\n",
    "\n",
    "# Randomly select indices from each array\n",
    "selected_indices_0 = np.random.choice(num_rows0, size=num_rows_to_select, replace=False)\n",
    "selected_indices_1 = np.random.choice(num_rows1, size=num_rows_to_select, replace=False)\n",
    "selected_indices_2 = np.random.choice(num_rows2, size=num_rows_to_select, replace=False)\n",
    "selected_indices_3 = np.random.choice(num_rows3, size=num_rows_to_select, replace=False)\n",
    "selected_indices_4 = np.random.choice(num_rows4, size=num_rows_to_select, replace=False)\n",
    "selected_indices_5 = np.random.choice(num_rows5, size=num_rows_to_select, replace=False)\n",
    "selected_indices_6 = np.random.choice(num_rows6, size=num_rows_to_select, replace=False)\n",
    "selected_indices_7 = np.random.choice(num_rows7, size=num_rows_to_select, replace=False)\n",
    "\n",
    "\n",
    "# Select rows from each array based on the randomly chosen indices\n",
    "selected_rows_0 = data0[selected_indices_0]\n",
    "y_train0 = np.zeros((num_rows_to_select, len(categories)))\n",
    "\n",
    "selected_rows_1 = data1[selected_indices_1]\n",
    "y_train1 = np.zeros((num_rows_to_select, len(categories)))\n",
    "\n",
    "selected_rows_2 = data2[selected_indices_2]\n",
    "y_train2 = np.zeros((num_rows_to_select, len(categories)))\n",
    "\n",
    "selected_rows_3 = data3[selected_indices_3]\n",
    "y_train3 = np.zeros((num_rows_to_select, len(categories)))\n",
    "\n",
    "selected_rows_4 = data4[selected_indices_4]\n",
    "y_train4 = np.zeros((num_rows_to_select, len(categories)))\n",
    "\n",
    "selected_rows_5 = data5[selected_indices_5]\n",
    "y_train5 = np.zeros((num_rows_to_select, len(categories)))\n",
    "\n",
    "selected_rows_6 = data6[selected_indices_6]\n",
    "y_train6 = np.zeros((num_rows_to_select, len(categories)))\n",
    "\n",
    "selected_rows_7 = data7[selected_indices_7]\n",
    "y_train7 = np.zeros((num_rows_to_select, len(categories)))\n",
    "\n",
    "# Concatenate the selected rows from all arrays\n",
    "data = np.concatenate((selected_rows_0, selected_rows_1,selected_rows_2,selected_rows_3,selected_rows_4,selected_rows_5,selected_rows_6, selected_rows_7), axis=0)\n",
    "y_train = np.concatenate((y_train0, y_train1, y_train2, y_train3, y_train4, y_train5, y_train6, y_train7), axis=0)\n",
    "\n",
    "u=0\n",
    "v=0\n",
    "row=0\n",
    "while u< len(categories) :\n",
    "    while v<num_rows_to_select:\n",
    "        row = num_rows_to_select * u\n",
    "        y_train[v+row][u] = 1\n",
    "        v+=1\n",
    "        \n",
    "    u+=1\n",
    "    v=0\n",
    "\n",
    "# Optionally, shuffle the merged array\n",
    "#np.random.shuffle(data)\n",
    "\n",
    "data.shape \n",
    "y_train.shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b444f852-9780-48a5-9308-1b84e4b61a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[899]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a596ba4-3091-4b88-99c3-d7a293ebd0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_small = np.concatenate((selected_rows_0[0:1000], selected_rows_1[0:1000],selected_rows_2[0:1000],selected_rows_3[0:1000],selected_rows_4[0:1000],selected_rows_5[0:1000],selected_rows_6[0:1000], selected_rows_7[0:1000]), axis=0)\n",
    "y_train_small = np.concatenate((y_train0[0:1000], y_train1[0:1000], y_train2[0:1000], y_train3[0:1000], y_train4[0:1000], y_train5[0:1000], y_train6[0:1000], y_train7[0:1000]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df47bd18-964a-412e-8ecd-c3bb2fca40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_selected = 1000\n",
    "u=0\n",
    "v=0\n",
    "row=0\n",
    "while u< len(categories) :\n",
    "    while v<n_selected:\n",
    "        row =  n_selected * u\n",
    "        y_train_small[v+row][u] = 1\n",
    "        v+=1\n",
    "        \n",
    "    u+=1\n",
    "    v=0\n",
    "\n",
    "y_train_small[799]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c50a5c-d4c9-45e3-87e0-edd570034ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1475e8-6f2a-473b-81bc-819219a5339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9404754-727a-41b9-9c72-97bacd2cc6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_small[899]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5eb230-7a62-41f8-8fbb-7bbe335f7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_small[899]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3378338-355a-468b-b56c-3f1d81c5383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([preprocess_image(img) for img in data_small])  \n",
    "y_train_part= y_train_small\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(categories))\n",
    "print (\"X_train shape = \", X_train.shape, \"y_train_part shape = \", y_train_part.shape)\n",
    "model.fit(X_train, y_train_part, epochs=5, batch_size=32)\n",
    "\n",
    "model.save(f\"{models_dir}mobilenet_doodle_recognition_8_cat_new_small.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7fbbc-0cb2-439c-9aab-43c7d17ad8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_med = np.concatenate((selected_rows_0[1000:6000], selected_rows_1[1000:6000],selected_rows_2[1000:6000],selected_rows_3[1000:6000],selected_rows_4[1000:6000],selected_rows_5[1000:6000],selected_rows_6[1000:6000], selected_rows_7[1000:6000]), axis=0)\n",
    "y_train_med = np.concatenate((y_train0[1000:6000], y_train1[1000:6000], y_train2[1000:6000], y_train3[1000:6000], y_train4[1000:6000], y_train5[1000:6000], y_train6[1000:6000], y_train7[1000:6000]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854fd57-9de3-4689-bb07-f6a062f708b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_selected = 5000\n",
    "u=0\n",
    "v=0\n",
    "row=0\n",
    "while u< len(categories) :\n",
    "    while v<n_selected:\n",
    "        row =  n_selected * u\n",
    "        y_train_med[v+row][u] = 1\n",
    "        v+=1\n",
    "        \n",
    "    u+=1\n",
    "    v=0\n",
    "\n",
    "y_train_med[5199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2814c910-3df2-4f88-938c-2427691e83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_med.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d8fc2-0e09-4d45-b504-c361ce99abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_med.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9433ff-29c3-4340-91ce-e6653027731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_med[11099]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be68a7-30a7-412a-9fdd-7bf069b0a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([preprocess_image(img) for img in data_med])  \n",
    "y_train_part= y_train_med\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(categories))\n",
    "print (\"X_train shape = \", X_train.shape, \"y_train_part shape = \", y_train_part.shape)\n",
    "model.fit(X_train, y_train_part, epochs=5, batch_size=32)\n",
    "\n",
    "model.save(f\"{models_dir}mobilenet_doodle_recognition_8_cat_new_med.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ba1bd-1e91-4c1a-b453-b661887b72e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "n = 0\n",
    "low=0\n",
    "high=0\n",
    "while n < 8:\n",
    "    low= n*1000\n",
    "    high = low+ 999\n",
    "    n+=1\n",
    "    print(\"low = \", low, \"high =\", high, \"n= \", n)\n",
    "    X_train = np.array([preprocess_image(img) for img in data_small[low:high]])  \n",
    "    y_train_part= y_train_small[low:high]\n",
    "    #y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(categories))\n",
    "    print (\"X_train shape = \", X_train.shape, \"y_train_part shape = \", y_train_part.shape)\n",
    "    model.fit(X_train, y_train_part, epochs=5, batch_size=32)\n",
    "    model.save(f\"{models_dir}mobilenet_doodle_recognition_8_cat_new_run_{n}.h5\")\n",
    "    model = tf.keras.models.load_model(f'{models_dir}/mobilenet_doodle_recognition_8_cat_new_run_{n}.h5')\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.save(f\"{models_dir}mobilenet_doodle_recognition_8_cat_new.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ade876-397d-4905-909f-084de3aa125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f'{models_dir}/mobilenet_doodle_recognition_8_cat_new_run_1.h5')\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ee4f0-67c0-4c21-bf06-a8df566ea7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "while n < 8:\n",
    "    low= n*1000\n",
    "    high = low+ 999\n",
    "    n+=1\n",
    "    print(\"low = \", low, \"high =\", high, \"n= \", n)\n",
    "    X_train = np.array([preprocess_image(img) for img in data_small[low:high]])  \n",
    "    y_train_part= y_train_small[low:high]\n",
    "    #y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(categories))\n",
    "    print (\"X_train shape = \", X_train.shape, \"y_train_part shape = \", y_train_part.shape)\n",
    "    model.fit(X_train, y_train_part, epochs=5, batch_size=32)\n",
    "    model.save(f\"{models_dir}mobilenet_doodle_recognition_8_cat_wt_run_{n}.h5\")\n",
    "    model.load_weights(f'{models_dir}/mobilenet_doodle_recognition_8_cat_wt_run_{n}.h5') \n",
    "  \n",
    "\n",
    "model.save(f\"{models_dir}mobilenet_doodle_recognition_8_cat_wt.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b0251-c8d3-4ee7-b19c-8dde903bab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81753df5-7eb1-4238-bdb6-67060b656087",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_8_model = tf.keras.models.load_model('models/mobilenet_doodle_recognition_8_cat_new_med.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb0d20-17dd-487c-aabf-90803e1b66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the image file\n",
    "img_file = 'images/apple2.png'  # Replace 'your_image.jpg' with the path to your image file\n",
    "\n",
    "img = cv2.imread(img_file)\n",
    "img = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "# Convert the image to single channel if necessary\n",
    "if len(img.shape) == 3:    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "print(img.shape)\n",
    "# Step 2: Reverse the preprocessing steps\n",
    "# Remove extra dimensions\n",
    "#img = np.squeeze(img)\n",
    "img_array = np.array(img)\n",
    "img_array = np.reshape(img_array, (784)) \n",
    "print(img_array.shape)\n",
    "\n",
    "# Resize the image to its original size\n",
    "img1 = cv2.resize(img_array, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "img1 = cv2.bitwise_not(img1)\n",
    "\n",
    "# Step 3: Convert the image to a NumPy array\n",
    "img_array = np.array(img1)\n",
    "#print(img_array)\n",
    "print(img_array.shape)\n",
    "plt.imshow(img_array.squeeze())\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = np.array(preprocess_input(img_array))\n",
    "img_array= np.expand_dims(img_array, axis=3)\n",
    "img_array = np.repeat(img_array, 3, axis=3)\n",
    "img_array = preprocess_input(img_array)\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f1c76-8e47-4412-8344-ad6b8b276cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = new_8_model.predict(img_array)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeba345-b759-4f6c-9c9b-31e792f83745",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = new_8_model.predict(img_array)\n",
    "categories[np.argmax(pred)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f1d0ac-a201-4ae0-b3ca-ad39165d222e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.imshow(test_img)\n",
    "test_img = data2[700]\n",
    "print (test_img.shape)\n",
    "test_img = cv2.resize(test_img, (224, 224), interpolation= cv2.INTER_AREA )\n",
    "plt.imshow(test_img.squeeze())\n",
    "test_img = np.expand_dims(test_img, axis=2)\n",
    "test_img = np.repeat(test_img, 3, axis=2)\n",
    "test_img = np.expand_dims(test_img, axis=0)\n",
    "test_img_array = np.array(preprocess_input(test_img))\n",
    "#print (test_img_array)\n",
    "test_img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36410b23-16f9-4113-9305-4baff9fd34d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image as im \n",
    "\n",
    "array = data2[700]\n",
    "print(array.shape) \n",
    "  \n",
    "# Reshape the array into a  \n",
    "# familiar resoluition \n",
    "array = np.reshape(array, (28, 28)) \n",
    "  \n",
    "# show the shape of the array \n",
    "print(array.shape) \n",
    "\n",
    "# creating image object of \n",
    "# above array \n",
    "data = im.fromarray(array) \n",
    "  \n",
    "data\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc84cbd4-abca-43f0-91dd-019f4342f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = im.open(\"images/airplane2.jpg\")\n",
    "size = (28, 28)\n",
    "img = img.thumbnail(size)\n",
    "img_array = np.array(img)\n",
    "\n",
    "img_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc402e8-9926-4bc8-bf45-9f94ce99a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = new_8_model.predict(test_img_array)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0707075e-a1d5-4607-9518-0ed5994c99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories[np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357c1d5-709b-4e44-8dbb-07b787493f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
